{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGv-TnYFn3mj"
   },
   "source": [
    "To speed the execution procces, Colaboraty has an option to use GPU. This option is selected by default.\n",
    "First of all we need to install two packages to show better the options of UFOD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (7.4.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/lib/python3/dist-packages (from ipywidgets) (4.3.2)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (7.3.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (3.4.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/lib/python3/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.2.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.0.9)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (41.0.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.3.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.13.3)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.3.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.4.0->ipywidgets) (5.7.6)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: jupyter-core in /usr/lib/python3/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/lib/python3/dist-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.2.4)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.11.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.3.4)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (5.4.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.8.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (18.0.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (2.10)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.14.11)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (19.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (3.1.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.4.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (1.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.5.1)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow of the UFOD framework\n",
    "\n",
    "The workflow of UFOD, depicted in the following image, captures all the necessary steps to train several object detection models and select the best one. Such a workflow can be summarised as follows. First of all, the user selects the dataset of images and some configuration parameters (mainly, the algorithms that will be trained and the frameworks or libraries that provide them). Subsequently, UFOD splits the dataset into a training set and a testing set. The training set is employed to construct several object detection models, and the best of those models is selected based on their performance on the testing set. The output of the framework is the best model, and an application, in the form of a Jupyter notebook, to employ such a model. Apart from the first step --- that is, the selection of the models to be trained --- the rest of the process is conducted automatically by UFOD without any user intervention. A more detailed explanation of the main features of this framework can be found in our [draft paper](https://github.com/ManuGar/UFOD/blob/master/draft.pdf).\n",
    "\n",
    "<img src=\"https://github.com/ManuGar/UFOD/raw/master/images/DiagramUFOD.png\" width=\"900\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9cG4swg6g6y"
   },
   "source": [
    "# How to use the framework\n",
    "\n",
    "To begin, we have to import all the classes that we will need to be able to use our framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTjifyh46g7A",
    "outputId": "a7a3e06b-25be-4c5e-87b2-6f1341ccc6eb"
   },
   "outputs": [],
   "source": [
    "import taskLauncher\n",
    "# import trainModel\n",
    "import factoryModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D51ZQMF56g7F"
   },
   "source": [
    "### Configuring the dataset path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0hhSw9W6g7G"
   },
   "source": [
    "The dataset needs to be annotated using the Pascal VOC format. An application that produces such a format is [LabelImg](https://github.com/tzutalin/labelImg). The folder containing the dataset must contain two folders:\n",
    "- JPEGImages folder: containing the images. \n",
    "- Annotations folder: containing the annotations using the Pascal format. \n",
    "\n",
    "This dataset will be later split. If the user wants to provide a explicit split, the organisation must be as follows:\n",
    "- train\n",
    "  - JPEGImages: folder containing the images of the training set. \n",
    "  - Annotations: folder containing the annotations of the training set. \n",
    "- test\n",
    "  - JPEGImages: folder containing the images of the testing set. \n",
    "  - Annotations: folder containing the annotations of the testing set.\n",
    " \n",
    "\n",
    "A dataset with this organization is provided in the [fruits folder](https://github.com/ManuGar/UFOD/tree/master/fruit) or [kangaro folder](https://www.dropbox.com/s/q19cl3agw8qt8e5/kangaroo.zip).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qak2xU1O6g7I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-14 19:47:11--  https://www.dropbox.com/s/q19cl3agw8qt8e5/kangaroo.zip?dl=0\n",
      "Resolviendo www.dropbox.com (www.dropbox.com)... 162.125.68.1, 2620:100:6024:1::a27d:4401\n",
      "Conectando con www.dropbox.com (www.dropbox.com)[162.125.68.1]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 301 Moved Permanently\n",
      "Ubicación: /s/raw/q19cl3agw8qt8e5/kangaroo.zip [siguiente]\n",
      "--2020-01-14 19:47:11--  https://www.dropbox.com/s/raw/q19cl3agw8qt8e5/kangaroo.zip\n",
      "Reutilizando la conexión con www.dropbox.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Ubicación: https://uc1982a5e177b1990c061e21d0df.dl.dropboxusercontent.com/cd/0/inline/AwI0s1howYz6Uld38o6y1bKhNhs4sHddDPCghAGbrUmRRAeG0xoUd-FOIvXPWzu3bMdTj-wHcbLkbOqaitDsgNVQdpcxz-vARvjRWAqwrjsjZFcmIkHYoHCLUN2ep_1cA_M/file# [siguiente]\n",
      "--2020-01-14 19:47:12--  https://uc1982a5e177b1990c061e21d0df.dl.dropboxusercontent.com/cd/0/inline/AwI0s1howYz6Uld38o6y1bKhNhs4sHddDPCghAGbrUmRRAeG0xoUd-FOIvXPWzu3bMdTj-wHcbLkbOqaitDsgNVQdpcxz-vARvjRWAqwrjsjZFcmIkHYoHCLUN2ep_1cA_M/file\n",
      "Resolviendo uc1982a5e177b1990c061e21d0df.dl.dropboxusercontent.com (uc1982a5e177b1990c061e21d0df.dl.dropboxusercontent.com)... 162.125.68.6, 2620:100:6024:6::a27d:4406\n",
      "Conectando con uc1982a5e177b1990c061e21d0df.dl.dropboxusercontent.com (uc1982a5e177b1990c061e21d0df.dl.dropboxusercontent.com)[162.125.68.6]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 FOUND\n",
      "Ubicación: /cd/0/inline2/AwI6Laf3uMyLtMBRYqYweq3aFLgvOW6fIHW-iY4nhfDDVNX_yz9DsuNgsGLah_95QsFnvZ3Cr8lYqjmQK2-CGtxIyW8bDlfU0cmLS7e3p7AareToH-nVsQLzbggu3SmDAEtAOz6hC7irKhCsQNN36CJ21-DE7kQL8xkQdl27_QjYsuk-QiJsWYeTAxxxMRERkSikNTF9orPUz0TO3Ke0f6JuYXwx9moGUjV_V5rCPXdYWZGeogtIAt0jVDj4ls1ja1qsyel6Ns3NOOZCQBg9wTZu3o8KkKTK49mYu3KzXsn6pvZTRk-fpec5t4P7OLje2ZSqg8vJ7fohU065FSQehcWZvJ5wwBj3idvf2yn5iSAF6Q/file [siguiente]\n",
      "--2020-01-14 19:47:13--  https://uc1982a5e177b1990c061e21d0df.dl.dropboxusercontent.com/cd/0/inline2/AwI6Laf3uMyLtMBRYqYweq3aFLgvOW6fIHW-iY4nhfDDVNX_yz9DsuNgsGLah_95QsFnvZ3Cr8lYqjmQK2-CGtxIyW8bDlfU0cmLS7e3p7AareToH-nVsQLzbggu3SmDAEtAOz6hC7irKhCsQNN36CJ21-DE7kQL8xkQdl27_QjYsuk-QiJsWYeTAxxxMRERkSikNTF9orPUz0TO3Ke0f6JuYXwx9moGUjV_V5rCPXdYWZGeogtIAt0jVDj4ls1ja1qsyel6Ns3NOOZCQBg9wTZu3o8KkKTK49mYu3KzXsn6pvZTRk-fpec5t4P7OLje2ZSqg8vJ7fohU065FSQehcWZvJ5wwBj3idvf2yn5iSAF6Q/file\n",
      "Reutilizando la conexión con uc1982a5e177b1990c061e21d0df.dl.dropboxusercontent.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 38903497 (37M) [application/zip]\n",
      "Guardando como: “kangaroo.zip”\n",
      "\n",
      "kangaroo.zip        100%[===================>]  37,10M  6,74MB/s    en 5,6s    \n",
      "\n",
      "2020-01-14 19:47:20 (6,68 MB/s) - “kangaroo.zip” guardado [38903497/38903497]\n",
      "\n",
      "Archive:  kangaroo.zip\n",
      "replace kangaroo/classes.names? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!wget \"https://www.dropbox.com/s/q19cl3agw8qt8e5/kangaroo.zip?dl=0\" -O kangaroo.zip\n",
    "!unzip kangaroo.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdwcQJUN6g7L"
   },
   "source": [
    "### Preparing the environment\n",
    "\n",
    "UFOD training process is configured by means a list of parameters, that must contain the following information:\n",
    "\n",
    "- \"dataset\": path to the dataset of images. \n",
    "- \"dataset_name\": a name to the dataset.\n",
    "- \"exec\": the execution mode. There are two execution modes:\n",
    "  - \"local\". The training process is run locally. In this option it is necessary to provide the number of available gpus with the \"ngpus\" parameter. \n",
    "  - \"slurm\". The training process is run in a cluster with SLURM. There are several parameters to configure in this option, such as the execution time (\"time\" parameter), the partition (\"partition\" parameter), the gres (\"gres\" parameter), the memory (\"mem\" parameter), or the number of gpus  (\"ngpus\" parameter).\n",
    "- \"frameworks\": the list of models to train. Currently, the following options are available:\n",
    "  - [\"Mxnet\",\"ssdVgg16\"]: SSD with the VGG16 backbone of the MXNet framework. \n",
    "  - [\"Mxnet\",\"ssdVgg16_512\"]: SSD with the VGG16 backbone and image size of 512 of the MXNet framework. \n",
    "  - [\"Mxnet\",\"ssdResnet\"]: SSD with the Resnet backbone of the MXNet framework.\n",
    "  - [\"Mxnet\",\"ssdMobilenet\"]: SSD with the mobilenet backbone of the MXNet framework.\n",
    "  - [\"Rcnn\",\"mask-rcnn\"]: Mask-RCNN algorithm using a Keras library. \n",
    "  - [\"Darknet\",\"yolo\"]: YOLO with the Darknet framework.\n",
    "  - [\"Darknet\",\"tinyYolo\"]: TinyYOLO with the Darknet framework.\n",
    "  - [\"Retinanet\",\"retinanet\"]: RetinaNet algorithm using a Keras library. \n",
    "  - [\"Tensorflow\", \"ssdInception\"]: SSD with the inception backbone using the Tensorflow framework.\n",
    "  - [\"Tensorflow\", \"fasterRcnnResnet\"]: Faster RCNN with the inception backbone using the Tensorflow framework.\n",
    "  - [\"Tensorflow\", \"rfcnResnet\"]: RFCN with the inception backbone using the Tensorflow framework.\n",
    "  - [\"Tensorflow\", \"maskRcnnInception\"]: Mask RCNN with the inception backbone using the Tensorflow framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-EX7rq36g7O"
   },
   "outputs": [],
   "source": [
    "dataset_path = widgets.Text(\n",
    "       value='./kangaroo',\n",
    "       description='Dataset path', )\n",
    "dataset_name = widgets.Text(\n",
    "       value='kangaroo',\n",
    "       description='Dataset name', )\n",
    "box = widgets.VBox([dataset_path, dataset_name])\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e44df877594cd1bbb92105f557c1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Checkbox(value=True, description='Mxnet-SsdVgg16'), Checkbox(value=True, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MxnetVgg16 = widgets.Checkbox(\n",
    "           description='Mxnet-SsdVgg16',value=True)\n",
    "MxnetVgg16_512 = widgets.Checkbox(\n",
    "           description='Mxnet-SsdVgg16_512',value=True)\n",
    "MxnetResnet = widgets.Checkbox(\n",
    "           description='Mxnet-SsdResnet',value=True)\n",
    "MxnetMobilenet = widgets.Checkbox(\n",
    "           description='Mxnet-SsdMobilenet',value=True)\n",
    "Mrcnn = widgets.Checkbox(\n",
    "           description='Mask-RCNN',value=True)\n",
    "Retinanet = widgets.Checkbox(\n",
    "           description='Retinanet',value=True)\n",
    "DarknetYolo = widgets.Checkbox(\n",
    "           description='Darknet-Yolo v3',value=True)\n",
    "DarknetTinyYolo = widgets.Checkbox(\n",
    "           description='Darknet-Tiny Yolo v3',value=True)\n",
    "TensorflowSsdInception = widgets.Checkbox(\n",
    "           description='Tensorflow-SsdInception',value=True)\n",
    "TensorflowfasterRcnnResnet = widgets.Checkbox(\n",
    "           description='Tensorflow-FasterRCNNRestnet',value=True)\n",
    "TensorflowRfcnResnet = widgets.Checkbox(\n",
    "           description='Tensorflow-RFCNResnet',value=True)\n",
    "TensorflowMaskRcnnInception = widgets.Checkbox(\n",
    "           description='Tensorflow-MaskRCNNInception',value=True)\n",
    "\n",
    "\n",
    "box1 = widgets.VBox([MxnetVgg16,MxnetVgg16_512,MxnetResnet,MxnetMobilenet])\n",
    "box2 = widgets.VBox([Mrcnn,Retinanet,DarknetYolo,DarknetTinyYolo])\n",
    "box3 = widgets.VBox([TensorflowSsdInception,\n",
    "                    TensorflowfasterRcnnResnet,TensorflowRfcnResnet,TensorflowMaskRcnnInception])\n",
    "\n",
    "frameworks=[]\n",
    "widgets.HBox([box1, box2,box3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b12f736841f4ec997dbd0f368172611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Execution type:', options=('local', 'slurm'), value='local')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(MxnetVgg16.value):\n",
    "    frameworks.append([\"Mxnet\",\"ssdVgg16\"])\n",
    "if(MxnetVgg16_512.value):\n",
    "    frameworks.append([\"Mxnet\",\"ssdVgg16_512\"])\n",
    "if(MxnetResnet.value):\n",
    "    frameworks.append([\"Mxnet\",\"ssdResnet\"])\n",
    "if(MxnetMobilenet.value):\n",
    "    frameworks.append([\"Mxnet\",\"ssdMobilenet\"])\n",
    "if(Mrcnn.value):\n",
    "    frameworks.append([\"Rcnn\",\"mask-rcnn\"])\n",
    "if(Retinanet.value):\n",
    "    frameworks.append([\"Retinanet\",\"retinanet\"])\n",
    "if(DarknetYolo.value):\n",
    "    frameworks.append([\"Darknet\",\"yolo\"])\n",
    "if(DarknetTinyYolo.value):\n",
    "    frameworks.append([\"Darknet\",\"tinyYolo\"])\n",
    "if(TensorflowSsdInception.value):\n",
    "    frameworks.append([\"Tensorflow\",\"ssdInception\"])\n",
    "if(TensorflowfasterRcnnResnet.value):\n",
    "    frameworks.append([\"Tensorflow\",\"fasterRcnnResnet\"])\n",
    "if(TensorflowMaskRcnnInception.value):\n",
    "    frameworks.append([\"Tensorflow\",\"rfcnResnet\"])\n",
    "if(TensorflowMaskRcnnInception.value):\n",
    "    frameworks.append([\"Tensorflow\",\"maskRcnnInception\"])\n",
    "\n",
    "\n",
    "\n",
    "type = widgets.Dropdown(\n",
    "    options=['local', 'slurm'],\n",
    "    value='local',\n",
    "    description='Execution type:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0de99f3003c4b45bcf8084a8fc37b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(BoundedIntText(value=1, description=\"Number GPU's:\", max=15, min=1),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_gpus = widgets.BoundedIntText(\n",
    "        value=1,\n",
    "        min=1,\n",
    "        max=15,\n",
    "        step=1,\n",
    "        description='Number GPU\\'s:',\n",
    "        disabled=False\n",
    "    )\n",
    "if type.value==\"slurm\":\n",
    "    time = widgets.Text(value='72:00:00',description='Time (HH:MM:SS)', )\n",
    "    partition = widgets.Text(value='gpu',description='Partition', )\n",
    "    gres = widgets.Text(value='gpu:kepler:2',description='Gres', )\n",
    "    mem = widgets.Text(value='56GB',description='Memmory', )\n",
    "    box1 =widgets.VBox([time, partition,gres])\n",
    "    box2 =widgets.VBox([mem, n_gpus])\n",
    "    newbox = widgets.HBox([box1,box2])\n",
    "elif type.value ==\"local\":\n",
    "    newbox = widgets.HBox([n_gpus])\n",
    "\n",
    "newbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to launch the training process\n",
    "\n",
    "Once the user has prepared the dataset and fixed the training options in the previous parameters, the training instructions are generated using the following command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!bash ./scripts/train_Mxnet_ssdVgg16_kangaroo.sh\n",
      "!bash ./scripts/train_Mxnet_ssdVgg16_512_kangaroo.sh\n",
      "!bash ./scripts/train_Mxnet_ssdResnet_kangaroo.sh\n",
      "!bash ./scripts/train_Mxnet_ssdMobilenet_kangaroo.sh\n",
      "!bash ./scripts/train_Rcnn_mask-rcnn_kangaroo.sh\n",
      "!bash ./scripts/train_Retinanet_retinanet_kangaroo.sh\n",
      "!bash ./scripts/train_Darknet_yolo_kangaroo.sh\n",
      "!bash ./scripts/train_Darknet_tinyYolo_kangaroo.sh\n",
      "!bash ./scripts/train_Tensorflow_ssdInception_kangaroo.sh\n",
      "!bash ./scripts/train_Tensorflow_fasterRcnnResnet_kangaroo.sh\n",
      "!bash ./scripts/train_Tensorflow_rfcnResnet_kangaroo.sh\n",
      "!bash ./scripts/train_Tensorflow_maskRcnnInception_kangaroo.sh\n"
     ]
    }
   ],
   "source": [
    "for fram, mod in frameworks:\n",
    "    file_name = os.path.join(\"./\",\"scripts\", \"train_\" + fram + \"_\" + mod + \"_\" + dataset_name.value + \".sh\")\n",
    "    f = open(file_name, \"w\")\n",
    "    f.write(\"#!/bin/sh\\n\")\n",
    "    if type ==\"slurm\":\n",
    "        if (fram == \"Mxnet\"):\n",
    "            f.write(\"source configs_slurm/mxnet.sh\\n\")\n",
    "        if (fram == \"Rcnn\"):\n",
    "            f.write(\"source configs_slurm/maskrcnn.sh\\n\")\n",
    "        if (fram == \"Retinanet\"):\n",
    "            f.write(\"source configs_slurm/retinanet.sh\\n\")\n",
    "        if (fram == \"Tensorflow\"):\n",
    "            f.write(\"source configs_slurm/tensorflow.sh\\n\")\n",
    "        if (fram == \"Darknet\"):\n",
    "            f.write(\"source configs_slurm/yolo.sh\\n\")\n",
    "    elif type ==\"local\":\n",
    "        if (fram == \"Mxnet\"):\n",
    "            f.write(\"source configs_local/mxnet.sh\\n\")\n",
    "        if (fram == \"Rcnn\"):\n",
    "            f.write(\"source configs_local/maskrcnn.sh\\n\")\n",
    "        if (fram == \"Retinanet\"):\n",
    "            f.write(\"source configs_local/retinanet.sh\\n\")\n",
    "        if (fram == \"Tensorflow\"):\n",
    "            f.write(\"source configs_local/tensorflow.sh\\n\")\n",
    "        if (fram == \"Darknet\"):\n",
    "            f.write(\"source configs_local/yolo.sh\\n\")\n",
    "    f.write(\"python3 trainModel.py -f \" + fram + \" -m \" + mod + \" -d \" + dataset_path.value + \" -dn \" + dataset_name.value + \" -ng \" + str(n_gpus.value))\n",
    "    if type.value == \"slurm\":\n",
    "        print(\"!\"+\"sbatch -p \" + partition + \" --gres=\" + gres + \" --time=\" + time+ \" --mem=\" + mem + \" \" + file_name )\n",
    "    elif type.value ==\"local\":\n",
    "        print(\"!bash \"+ file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can copy the instructions generated in the following cell and run the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1211 18:17:57.888797 140280827893568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1211 18:17:57.930413 140280827893568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1211 18:17:57.959913 140280827893568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1211 18:17:57.996255 140280827893568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1211 18:17:57.999652 140280827893568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1211 18:17:59.464108 140280827893568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W1211 18:18:00.470711 140280827893568 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1211 18:18:00.628417 140280827893568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:554: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "W1211 18:18:00.703052 140280827893568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mrcnn/utils.py:201: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1211 18:18:00.729085 140280827893568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:601: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "2019-12-11 18:18:03.973315: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-11 18:18:04.014232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1800000000 Hz\n",
      "2019-12-11 18:18:04.015902: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb46c290 executing computations on platform Host. Devices:\n",
      "2019-12-11 18:18:04.015963: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-12-11 18:18:05.918896: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "W1211 18:18:07.150541 140280827893568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
      "Epoch 1/5\n",
      "2019-12-11 18:18:52.854814: W tensorflow/core/framework/allocator.cc:107] Allocation of 642252800 exceeds 10% of system memory.\n",
      "terminate called after throwing an instance of 'std::bad_alloc'\n",
      "  what():  std::bad_alloc\n",
      "^C\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/train_Rcnn_mask-rcnn_kangaroo.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HowToUse.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
